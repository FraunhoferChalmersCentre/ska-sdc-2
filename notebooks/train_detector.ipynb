{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add project root to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import filename\n",
    "from utils import filehandling\n",
    "\n",
    "size = 'dev_l'\n",
    "cube_side = 32\n",
    "transform = 'minmax'\n",
    "prob = 50\n",
    "\n",
    "directory = filename.processed.dataset(size, cube_side, transform, prob)\n",
    "dataset = filehandling.read_splitted_dataset(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import splitting\n",
    "\n",
    "train, test = splitting.train_val_split(dataset, .8)\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained 2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(encoder_name='resnet101', in_channels=1, classes=1, encoder_weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert pretrained 2D model to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch\n",
    "from training.convert2Dto3D import Conv3dConverter\n",
    "\n",
    "Conv3dConverter(model, -1, torch.ones(1, 1, 32, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seg = train.get_attribute('segmentmap')\n",
    "threshold = 0.5#sum(map(torch.sum, seg)) / sum(map(lambda t: torch.prod(torch.tensor(t.shape)),seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "model_id = filename.models.new_id()\n",
    "checkpoint_callback = ModelCheckpoint(monitor='Jaccard',save_top_k=1, dirpath=filename.models.directory,\n",
    "                                      filename=str(model_id) +'-{epoch:02d}-{Jaccard:.2f}', mode='max', period=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data.generating import get_hi_shape\n",
    "from utils import filename\n",
    "hi_shape = get_hi_shape(filename.data.sky(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Lightning objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from datetime import datetime\n",
    "from pytorch_toolbelt import losses\n",
    "\n",
    "from training.segmentation import Segmenter, get_vis_id\n",
    "\n",
    "min_vis_voxels = 300\n",
    "vis_id = get_vis_id(test, hi_shape, min_vis_voxels)\n",
    "\n",
    "loss = losses.JointLoss(losses.JaccardLoss(mode='binary', log_loss=True), losses.SoftBCEWithLogitsLoss())\n",
    "\n",
    "version = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"segmenter\", version=version)\n",
    "segmenter = Segmenter(model, loss, train, test, vis_id=vis_id, threshold=threshold, lr=1e-2)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=500, gpus=1, logger=logger, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(segmenter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
