{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b12c1d",
   "metadata": {},
   "source": [
    "Add project root to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dbf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54afa376",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26adb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import filename\n",
    "from utils import filehandling\n",
    "\n",
    "size = 'dev_s'\n",
    "prob = 50\n",
    "\n",
    "directory = filename.processed.dataset(size, prob)\n",
    "dataset = filehandling.read_splitted_dataset(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e84d3",
   "metadata": {},
   "source": [
    "Split to train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08969c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.data import splitting\n",
    "\n",
    "random_state = np.random.RandomState(5)\n",
    "train, test = splitting.train_val_split(dataset, .8, random_state=random_state, train_filter=None)\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a1f95",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pipeline.convert2Dto3D import Conv3dConverter\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(encoder_name='resnet18', in_channels=1, classes=1, encoder_weights='swsl')\n",
    "# Convert pretrained 2D model to 3D\n",
    "Conv3dConverter(model, -1, (32, 1, 32, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c98ee",
   "metadata": {},
   "source": [
    "Convert pretrained 2D model to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seg = train.get_attribute('segmentmap')\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9caa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "model_id = filename.models.new_id()\n",
    "checkpoint_callback = ModelCheckpoint(monitor='sofia_dice', save_top_k=1, dirpath=filename.models.directory,\n",
    "                                      filename=str(model_id) + '-{epoch:02d}-{sofia_dice:.2f}', mode='max', period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc73181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "from utils.data.generating import get_hi_shape\n",
    "from utils import filename\n",
    "\n",
    "hi_shape = get_hi_shape(filename.data.sky(size))\n",
    "header = fits.getheader(filename.data.sky(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c72b94",
   "metadata": {},
   "source": [
    "Create Lightning objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cfee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from datetime import datetime\n",
    "from pytorch_toolbelt import losses\n",
    "from pipeline.segmenter import BaseSegmenter\n",
    "from training.train_segmenter import TrainSegmenter, get_random_vis_id\n",
    "\n",
    "min_vis_voxels = 500\n",
    "vis_id = get_random_vis_id(test, hi_shape, min_vis_voxels, random_state=np.random.RandomState(10))\n",
    "\n",
    "loss = losses.JointLoss(losses.DiceLoss(mode='binary', log_loss=True), losses.SoftBCEWithLogitsLoss(), 1.0, 1.0)\n",
    "\n",
    "version = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"resnet\", version=version)\n",
    "base_segmenter = BaseSegmenter(model, train.get_attribute('scale'), train.get_attribute('mean'),\n",
    "                               train.get_attribute('std'))\n",
    "segmenter = TrainSegmenter(base_segmenter, loss, train, test, header, vis_id=vis_id, threshold=threshold, lr=1e-2,\n",
    "                           batch_size=128)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100000, gpus=0, logger=logger, callbacks=[checkpoint_callback],\n",
    "                     check_val_every_n_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df261150",
   "metadata": {},
   "source": [
    "Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e169d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(segmenter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
